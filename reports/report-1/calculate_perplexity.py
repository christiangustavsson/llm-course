"""
Calculate perplexity of cleaned text files using a simple n-gram model.

This script loads the cleaned text files and calculates their perplexity
using a basic n-gram language model.

Note: This script is generated by Cursor Agent using Claude 3.5 Sonnet
and is not my own work. It's used for demonstration purposes.

"""

import os
import math
import re
from collections import defaultdict, Counter

def load_text(file_path):
    """Load text from a file."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

def tokenize(text):
    """Simple word tokenization."""
    # Convert to lowercase and split into words
    words = re.findall(r'\b\w+\b', text.lower())
    return words

def create_ngrams(tokens, n):
    """Create n-grams from a list of tokens."""
    ngrams = []
    for i in range(len(tokens) - n + 1):
        ngram = tuple(tokens[i:i + n])
        ngrams.append(ngram)
    return ngrams

def calculate_perplexity(text, n=2):
    """
    Calculate perplexity using a simple n-gram model.
    
    Args:
        text: The text to calculate perplexity for
        n: The order of n-grams to use
        
    Returns:
        The perplexity score
    """
    # Tokenize text
    tokens = tokenize(text)
    if len(tokens) < n:
        return float('inf')
    
    # Create n-grams
    ngrams = create_ngrams(tokens, n)
    
    # Count n-grams and (n-1)-grams
    ngram_counts = Counter(ngrams)
    context_counts = Counter(tuple(ng[:-1]) for ng in ngrams)
    
    # Calculate log probability
    total_log_prob = 0
    total_words = len(tokens) - n + 1
    
    for ngram in ngrams:
        context = ngram[:-1]
        word = ngram[-1]
        
        # Calculate probability with simple smoothing
        prob = (ngram_counts[ngram] + 0.1) / (context_counts[context] + 0.1 * len(set(tokens)))
        total_log_prob += math.log2(prob)
    
    # Calculate perplexity
    avg_log_prob = total_log_prob / total_words
    perplexity = 2 ** (-avg_log_prob)
    
    return perplexity

def main():
    # Get script directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # Process website data files
    print("\nProcessing website data:")
    print("-" * 40)
    
    # Raw website data
    raw_web_path = os.path.join(script_dir, "raw_website_data.txt")
    if os.path.exists(raw_web_path):
        raw_web_text = load_text(raw_web_path)
        raw_web_perplexity = calculate_perplexity(raw_web_text)
        print(f"Raw website perplexity: {raw_web_perplexity:.2f}")
    else:
        print(f"Raw website file not found: {raw_web_path}")
    
    # Clean website data
    clean_web_path = os.path.join(script_dir, "clean_website_data.txt")
    if os.path.exists(clean_web_path):
        clean_web_text = load_text(clean_web_path)
        clean_web_perplexity = calculate_perplexity(clean_web_text)
        print(f"Clean website perplexity: {clean_web_perplexity:.2f}")
    else:
        print(f"Clean website file not found: {clean_web_path}")
    
    # Process PDF data files
    print("\nProcessing PDF data:")
    print("-" * 40)
    
    # Raw PDF data
    raw_pdf_path = os.path.join(script_dir, "raw_pdf_data.txt")
    if os.path.exists(raw_pdf_path):
        raw_pdf_text = load_text(raw_pdf_path)
        raw_pdf_perplexity = calculate_perplexity(raw_pdf_text)
        print(f"Raw PDF perplexity: {raw_pdf_perplexity:.2f}")
    else:
        print(f"Raw PDF file not found: {raw_pdf_path}")
    
    # Clean PDF data
    clean_pdf_path = os.path.join(script_dir, "clean_pdf_data.txt")
    if os.path.exists(clean_pdf_path):
        clean_pdf_text = load_text(clean_pdf_path)
        clean_pdf_perplexity = calculate_perplexity(clean_pdf_text)
        print(f"Clean PDF perplexity: {clean_pdf_perplexity:.2f}")
    else:
        print(f"Clean PDF file not found: {clean_pdf_path}")

if __name__ == "__main__":
    main() 